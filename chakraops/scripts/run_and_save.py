#!/usr/bin/env python3
# Copyright 2026 ChakraOps
# SPDX-License-Identifier: MIT
"""Single source of truth for decision snapshots. Uses staged evaluator pipeline.

Read-only: no broker calls. Writes timestamped copies to --output-dir.
Latest (decision_latest.json) is written ONLY by EvaluationStoreV2 to canonical path
<REPO_ROOT>/out/decision_latest.json.

Usage:
  cd chakraops
  $env:PYTHONPATH=(Get-Location).Path
  python scripts/run_and_save.py --symbols SPY,AAPL --output-dir out
  python scripts/run_and_save.py --realtime --interval 30
"""

from __future__ import annotations

import argparse
import json
import sys
import time
from dataclasses import asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

_REPO_ROOT = Path(__file__).resolve().parents[1]
if str(_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_REPO_ROOT))

try:
    from dotenv import load_dotenv
    load_dotenv(_REPO_ROOT / ".env")
except ImportError:
    pass

DEFAULT_SYMBOLS = ["SPY", "AAPL"]


def _band_from_hint(capital_hint: Any, score: int) -> str:
    """Derive band A/B/C/NONE from capital_hint or score."""
    if capital_hint and isinstance(capital_hint, dict):
        band = capital_hint.get("band")
        if band in ("A", "B", "C"):
            return band
    if score >= 80:
        return "A"
    if score >= 60:
        return "B"
    if score >= 40:
        return "C"
    return "NONE"


def _build_decision_artifact_from_evaluation(eval_result: Any) -> Dict[str, Any]:
    """Convert UniverseEvaluationResult to decision artifact shape for Live Decision Monitor."""
    ts = datetime.now(timezone.utc).isoformat()
    symbols = getattr(eval_result, "symbols", []) or []
    evaluated = len([s for s in symbols if getattr(s, "verdict", None) is not None])
    shortlisted = len([s for s in symbols if getattr(s, "candidate_trades", None)])

    candidates: List[Dict[str, Any]] = []
    selected_signals: List[Dict[str, Any]] = []
    exclusions: List[Dict[str, Any]] = []

    symbol_summaries: List[Dict[str, Any]] = []
    for s in symbols:
        sym = getattr(s, "symbol", "?") or "?"
        verdict = str(getattr(s, "verdict", "") or "")
        reason = getattr(s, "primary_reason", None) or ""
        cds = getattr(s, "candidate_trades", []) or []
        stage_reached = getattr(s, "stage_reached", "") or "STAGE1_ONLY"
        sc = getattr(s, "selected_contract", None) or {}
        strategy = (sc.get("strategy") if isinstance(sc, dict) else None) or (cds[0].strategy if cds else None)
        band = _band_from_hint(getattr(s, "capital_hint", None), getattr(s, "score", 0))
        symbol_summaries.append({
            "symbol": sym,
            "verdict": verdict,
            "score": getattr(s, "score", 0),
            "band": band,
            "primary_reason": reason or "",
            "strategy": strategy if strategy else None,
            "stage1_status": "STAGE2" if stage_reached == "STAGE2_CHAIN" else "STAGE1",
            "stage2_status": "PASS" if (getattr(s, "liquidity_ok", False) and stage_reached == "STAGE2_CHAIN") else ("SKIP" if stage_reached != "STAGE2_CHAIN" else "FAIL"),
            "provider_status": "OK" if (getattr(s, "data_completeness", 0) or 0) >= 0.75 else "INCOMPLETE",
            "data_freshness": getattr(s, "quote_date", None) or getattr(s, "fetched_at", None),
            "evaluated_at": getattr(s, "fetched_at", None) or ts,
        })
        for ct in cds:
            ct_dict = asdict(ct) if hasattr(ct, "__dataclass_fields__") else (ct if isinstance(ct, dict) else {})
            candidates.append({"symbol": sym, "verdict": verdict, "candidate": ct_dict})
        if verdict.upper() == "ELIGIBLE" and cds:
            first = cds[0]
            ct_dict = asdict(first) if hasattr(first, "__dataclass_fields__") else (first if isinstance(first, dict) else {})
            selected_signals.append({"symbol": sym, "candidate": ct_dict, "verdict": verdict})
        if verdict.upper() not in ("ELIGIBLE", "HOLD") and reason:
            exclusions.append({"symbol": sym, "reason": reason})

    return {
        "decision_snapshot": {
            "stats": {
                "symbols_evaluated": evaluated,
                "total_candidates": shortlisted,
                "selected_count": len(selected_signals),
            },
            "candidates": candidates,
            "selected_signals": selected_signals,
            "exclusions": exclusions,
            "data_source": "evaluation_pipeline",
            "as_of": ts,
            "pipeline_timestamp": ts,
            "trade_proposal": None,
            "why_no_trade": {"summary": "Generated by scripts/run_and_save.py (read-only evaluation)"},
        },
        "execution_gate_result": {"allowed": False, "reasons": ["Snapshot generator — no live execution"]},
        "execution_gate": {"allowed": False, "reasons": ["Snapshot generator — no live execution"]},
        "execution_plan": {"allowed": False, "blocked_reason": "Snapshot generator", "orders": []},
        "dry_run_result": {"allowed": False},
        "metadata": {
            "data_source": "run_and_save",
            "pipeline_timestamp": ts,
        },
        "symbol_summaries": symbol_summaries,
    }


def _resolve_symbols(args: argparse.Namespace) -> List[str]:
    """Resolve symbol list from CLI or defaults. No DB dependency."""
    if getattr(args, "all", False):
        try:
            from app.api.data_health import get_universe_symbols
            return list(get_universe_symbols())
        except Exception as e:
            raise RuntimeError(f"Failed to load universe: {e}") from e
    if args.symbols:
        symbols = [s.strip().upper() for s in args.symbols.split(",") if s.strip()]
    else:
        try:
            from app.api.data_health import get_universe_symbols
            all_syms = get_universe_symbols()
            symbols = all_syms[: args.limit]
        except Exception:
            symbols = (DEFAULT_SYMBOLS * 2)[: args.limit]
    return symbols or DEFAULT_SYMBOLS.copy()


def run_one(args: argparse.Namespace, out_dir: Path) -> Tuple[int, Optional[Path]]:
    """Run staged evaluation once and write DecisionArtifactV2. Returns (exit_code, path_written)."""
    symbols = _resolve_symbols(args)
    if not symbols:
        print("No symbols to evaluate")
        return 1, None

    if getattr(args, "all", False):
        print(f"[RUN] Evaluating full universe ({len(symbols)} symbols)")
    else:
        print(f"Evaluating {len(symbols)} symbols: {symbols}")

    try:
        from app.core.eval.evaluation_service_v2 import evaluate_universe
        from app.core.eval.evaluation_store_v2 import get_decision_store_path
        # evaluate_universe writes to canonical DECISION_STORE_PATH via store
        artifact = evaluate_universe(symbols, mode="LIVE")
    except Exception as e:
        print(f"Evaluation failed: {e}")
        return 1, None

    ts = datetime.now(timezone.utc)
    fname = f"decision_{ts.strftime('%Y-%m-%dT%H%M%S')}Z.json"
    out_path = out_dir / fname
    artifact_dict = artifact.to_dict()
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(artifact_dict, f, indent=2, default=str)
    latest_path = get_decision_store_path()
    print(f"Wrote {out_path}")
    print(f"Latest: {latest_path} (v2, written by store)")
    return 0, out_path


def enforce_retention(output_dir: Path, max_days: int = 7) -> Tuple[int, List[str]]:
    """Delete old timestamped decision files beyond retention. Keep decision_latest.json."""
    from datetime import date, timedelta
    keep = {"decision_latest.json", "sample_decision.json", "sample_decision_rich.json"}
    files = [f for f in output_dir.glob("decision_*.json") if f.name not in keep]
    if not files:
        return 0, []
    cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=max_days)).timestamp()
    deleted: List[str] = []
    for f in files:
        try:
            if f.stat().st_mtime < cutoff_ts:
                f.unlink()
                deleted.append(f.name)
        except Exception as e:
            print(f"  Warning: failed to delete {f.name}: {e}", file=sys.stderr)
    return len(deleted), deleted


def main() -> int:
    parser = argparse.ArgumentParser(description="Run staged evaluation and save decision snapshots")
    parser.add_argument("--symbols", type=str, default=None, help="Comma-separated symbols (default: SPY,AAPL)")
    parser.add_argument("--limit", type=int, default=5, help="Max symbols when using universe (default: 5)")
    parser.add_argument("--all", action="store_true", help="Evaluate entire universe")
    parser.add_argument("--output-dir", type=str, default="out", help="Output directory (default: out)")
    parser.add_argument("--realtime", action="store_true", help="Loop: update decision_latest.json every interval")
    parser.add_argument("--interval", type=int, default=30, help="Refresh interval in seconds (default: 30)")
    parser.add_argument("--skip-cleanup", action="store_true", help="Skip retention cleanup")
    args = parser.parse_args()

    if args.all and args.symbols:
        raise ValueError("Cannot use --all and --symbols together")

    # Canonical out dir = parent of decision_latest.json (same as store)
    try:
        from app.core.eval.evaluation_store_v2 import get_decision_store_path
        _canonical_out = get_decision_store_path().parent
    except Exception:
        _canonical_out = _REPO_ROOT / "out"
    out_dir = Path(args.output_dir)
    if not out_dir.is_absolute():
        if out_dir == Path("out") or str(out_dir) == "out":
            out_dir = _canonical_out
        else:
            out_dir = (_canonical_out.parent / out_dir).resolve()
    out_dir.mkdir(parents=True, exist_ok=True)

    if args.realtime:
        print("Realtime mode: Ctrl+C to stop")
        try:
            while True:
                run_one(args, out_dir)
                if not args.skip_cleanup:
                    n, _ = enforce_retention(out_dir)
                    if n > 0:
                        print(f"  Cleanup: deleted {n} old file(s)")
                time.sleep(args.interval)
        except KeyboardInterrupt:
            print("\nStopped")
        return 0

    exit_code, _ = run_one(args, out_dir)
    if exit_code != 0:
        return exit_code
    if not args.skip_cleanup:
        n, _ = enforce_retention(out_dir)
        if n > 0:
            print(f"  Cleanup: deleted {n} old file(s)")
    return 0


if __name__ == "__main__":
    sys.exit(main())
