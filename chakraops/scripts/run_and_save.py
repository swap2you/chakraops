#!/usr/bin/env python3
# Copyright 2026 ChakraOps
# SPDX-License-Identifier: MIT
"""Single source of truth for decision snapshots. Uses staged evaluator pipeline.

Read-only: no broker calls. Writes out/decision_<timestamp>.json and out/decision_latest.json.

Usage:
  cd chakraops
  $env:PYTHONPATH=(Get-Location).Path
  python scripts/run_and_save.py --symbols SPY,AAPL --output-dir out
  python scripts/run_and_save.py --realtime --interval 30
"""

from __future__ import annotations

import argparse
import json
import sys
import time
from dataclasses import asdict
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

_REPO_ROOT = Path(__file__).resolve().parents[1]
if str(_REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(_REPO_ROOT))

try:
    from dotenv import load_dotenv
    load_dotenv(_REPO_ROOT / ".env")
except ImportError:
    pass

DEFAULT_SYMBOLS = ["SPY", "AAPL"]


def _build_decision_artifact_from_evaluation(eval_result: Any) -> Dict[str, Any]:
    """Convert UniverseEvaluationResult to decision artifact shape for Live Decision Monitor."""
    ts = datetime.now(timezone.utc).isoformat()
    symbols = getattr(eval_result, "symbols", []) or []
    evaluated = len([s for s in symbols if getattr(s, "verdict", None) is not None])
    shortlisted = len([s for s in symbols if getattr(s, "candidate_trades", None)])

    candidates: List[Dict[str, Any]] = []
    selected_signals: List[Dict[str, Any]] = []
    exclusions: List[Dict[str, Any]] = []

    for s in symbols:
        sym = getattr(s, "symbol", "?") or "?"
        verdict = str(getattr(s, "verdict", "") or "")
        reason = getattr(s, "primary_reason", None) or ""
        cds = getattr(s, "candidate_trades", []) or []
        for ct in cds:
            ct_dict = asdict(ct) if hasattr(ct, "__dataclass_fields__") else (ct if isinstance(ct, dict) else {})
            candidates.append({"symbol": sym, "verdict": verdict, "candidate": ct_dict})
        if verdict.upper() == "ELIGIBLE" and cds:
            first = cds[0]
            ct_dict = asdict(first) if hasattr(first, "__dataclass_fields__") else (first if isinstance(first, dict) else {})
            selected_signals.append({"symbol": sym, "candidate": ct_dict, "verdict": verdict})
        if verdict.upper() not in ("ELIGIBLE", "HOLD") and reason:
            exclusions.append({"symbol": sym, "reason": reason})

    return {
        "decision_snapshot": {
            "stats": {
                "symbols_evaluated": evaluated,
                "total_candidates": shortlisted,
                "selected_count": len(selected_signals),
            },
            "candidates": candidates,
            "selected_signals": selected_signals,
            "exclusions": exclusions,
            "data_source": "evaluation_pipeline",
            "as_of": ts,
            "pipeline_timestamp": ts,
            "trade_proposal": None,
            "why_no_trade": {"summary": "Generated by scripts/run_and_save.py (read-only evaluation)"},
        },
        "execution_gate_result": {"allowed": False, "reasons": ["Snapshot generator — no live execution"]},
        "execution_gate": {"allowed": False, "reasons": ["Snapshot generator — no live execution"]},
        "execution_plan": {"allowed": False, "blocked_reason": "Snapshot generator", "orders": []},
        "dry_run_result": {"allowed": False},
        "metadata": {
            "data_source": "run_and_save",
            "pipeline_timestamp": ts,
        },
    }


def _resolve_symbols(args: argparse.Namespace) -> List[str]:
    """Resolve symbol list from CLI or defaults. No DB dependency."""
    if args.symbols:
        symbols = [s.strip().upper() for s in args.symbols.split(",") if s.strip()]
    else:
        try:
            from app.api.data_health import get_universe_symbols
            all_syms = get_universe_symbols()
            symbols = all_syms[: args.limit]
        except Exception:
            symbols = (DEFAULT_SYMBOLS * 2)[: args.limit]
    return symbols or DEFAULT_SYMBOLS.copy()


def run_one(args: argparse.Namespace, out_dir: Path) -> Tuple[int, Optional[Path]]:
    """Run staged evaluation once and write decision artifacts. Returns (exit_code, path_written)."""
    symbols = _resolve_symbols(args)
    if not symbols:
        print("No symbols to evaluate")
        return 1, None

    print(f"Evaluating {len(symbols)} symbols: {symbols}")

    try:
        from app.core.eval.universe_evaluator import run_universe_evaluation_staged
        result = run_universe_evaluation_staged(symbols, use_staged=True)
    except Exception as e:
        print(f"Evaluation failed: {e}")
        return 1, None

    artifact = _build_decision_artifact_from_evaluation(result)
    ts = datetime.now(timezone.utc)
    fname = f"decision_{ts.strftime('%Y-%m-%dT%H%M%S')}Z.json"
    out_path = out_dir / fname
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(artifact, f, indent=2)

    latest_path = out_dir / "decision_latest.json"
    with open(latest_path, "w", encoding="utf-8") as f:
        json.dump(artifact, f, indent=2)

    print(f"Wrote {out_path}")
    print(f"Latest: {latest_path}")
    return 0, out_path


def enforce_retention(output_dir: Path, max_days: int = 7) -> Tuple[int, List[str]]:
    """Delete old timestamped decision files beyond retention. Keep decision_latest.json."""
    from datetime import date, timedelta
    keep = {"decision_latest.json", "sample_decision.json", "sample_decision_rich.json"}
    files = [f for f in output_dir.glob("decision_*.json") if f.name not in keep]
    if not files:
        return 0, []
    cutoff_ts = (datetime.now(timezone.utc) - timedelta(days=max_days)).timestamp()
    deleted: List[str] = []
    for f in files:
        try:
            if f.stat().st_mtime < cutoff_ts:
                f.unlink()
                deleted.append(f.name)
        except Exception as e:
            print(f"  Warning: failed to delete {f.name}: {e}", file=sys.stderr)
    return len(deleted), deleted


def main() -> int:
    parser = argparse.ArgumentParser(description="Run staged evaluation and save decision snapshots")
    parser.add_argument("--symbols", type=str, default=None, help="Comma-separated symbols (default: SPY,AAPL)")
    parser.add_argument("--limit", type=int, default=5, help="Max symbols when using universe (default: 5)")
    parser.add_argument("--output-dir", type=str, default="out", help="Output directory (default: out)")
    parser.add_argument("--realtime", action="store_true", help="Loop: update decision_latest.json every interval")
    parser.add_argument("--interval", type=int, default=30, help="Refresh interval in seconds (default: 30)")
    parser.add_argument("--skip-cleanup", action="store_true", help="Skip retention cleanup")
    args = parser.parse_args()

    out_dir = Path(args.output_dir)
    if not out_dir.is_absolute():
        out_dir = _REPO_ROOT / out_dir
    out_dir.mkdir(parents=True, exist_ok=True)

    if args.realtime:
        print("Realtime mode: Ctrl+C to stop")
        try:
            while True:
                run_one(args, out_dir)
                if not args.skip_cleanup:
                    n, _ = enforce_retention(out_dir)
                    if n > 0:
                        print(f"  Cleanup: deleted {n} old file(s)")
                time.sleep(args.interval)
        except KeyboardInterrupt:
            print("\nStopped")
        return 0

    exit_code, _ = run_one(args, out_dir)
    if exit_code != 0:
        return exit_code
    if not args.skip_cleanup:
        n, _ = enforce_retention(out_dir)
        if n > 0:
            print(f"  Cleanup: deleted {n} old file(s)")
    return 0


if __name__ == "__main__":
    sys.exit(main())
